{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "887458b4",
    "outputId": "745913a4-ac57-42bd-b815-d8be40d2fa62"
   },
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Kaggle kimlik bilgilerini ortam değişkenlerine ayarla\n",
    "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
    "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
    "\n",
    "print(\"Kaggle kimlik bilgileri başarıyla ayarlandı.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8425c2c0",
    "outputId": "1241da52-e923-47fa-91f7-c4f939003f8d"
   },
   "source": [
    "# Veri setini indir\n",
    "!kaggle datasets download -d ipythonx/mvtec-ad\n",
    "\n",
    "# İndirilen zip dosyasını aç\n",
    "!unzip mvtec-ad.zip -d /content/mvtec-ad\n",
    "\n",
    "print(\"Veri seti başarıyla indirildi ve açıldı.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)"
   ],
   "metadata": {
    "id": "ByJEXw39yYGJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def load_images(data_path, img_size=(256, 256)):\n",
    "    images = []\n",
    "    for img_file in Path(data_path).glob('**/*.png'):\n",
    "        img = cv2.imread(str(img_file))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "#Büyük işlemlerde DataLoader kullanmak ram için daha verimli\n",
    "category = 'leather'  # kategori\n",
    "train_path = f'/content/mvtec-ad/{category}/train/good'\n",
    "\n",
    "train_images = load_images(train_path)"
   ],
   "metadata": {
    "id": "uoM3Ug39yu2n"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def build_autoencoder(input_shape=(256, 256, 3)):\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    decoded = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = keras.Model(encoder_input, decoded)\n",
    "    return autoencoder\n",
    "\n",
    "model = build_autoencoder()\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "CzEgddfkyyos",
    "outputId": "7fb454f3-107f-4537-a062-a3a57b76c611"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model derleme\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ssim_loss,  # SSIM loss kullanıldı\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Eğitim\n",
    "history = model.fit(\n",
    "    train_images, train_images,  # Input ve output aynı\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Modeli kaydetme (Legacy format düzeltildi: .h5 -> .keras)\n",
    "model.save('autoencoder_model.keras')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_anomaly_scores(model, images):\n",
    "    \"\"\"\n",
    "    Verilen görüntüler için modelin rekonstrüksiyonuna göre\n",
    "    SSIM tabanlı anomali skorlarını hesaplar.\n",
    "    Skor = 1 - SSIM (0'a yakınsa iyi, 1'e yakınsa kötü/anomali)\n",
    "    \"\"\"\n",
    "    reconstructed = model.predict(images, verbose=0)\n",
    "    # TF SSIM hesaplaması\n",
    "    # SSIM (Batch, ) boyutunda bir tensör döndürür\n",
    "    ssim_values = tf.image.ssim(images, reconstructed, max_val=1.0)\n",
    "    # Loss'a çeviriyoruz (Anomali skoru)\n",
    "    scores = 1.0 - ssim_values.numpy()\n",
    "    return scores, reconstructed\n",
    "\n",
    "def detect_anomalies(model, test_images, threshold):\n",
    "    \"\"\"\n",
    "    Belirlenen threshold'a göre anomali tespiti yapar.\n",
    "    \"\"\"\n",
    "    scores, reconstructed = calculate_anomaly_scores(model, test_images)\n",
    "    is_anomaly = scores > threshold\n",
    "    return scores, is_anomaly, reconstructed\n",
    "\n",
    "# 1. Threshold Hesaplama (TEMİZ EĞİTİM SETİ ÜZERİNDEN)\n",
    "# Issue Düzeltmesi: Threshold test setinden değil, train setinden hesaplanmalı.\n",
    "print(\"Threshold temiz eğitim seti üzerinden hesaplanıyor...\")\n",
    "train_scores, _ = calculate_anomaly_scores(model, train_images)\n",
    "\n",
    "# Ortalama + 2 Standart Sapma (veya 3) kuralı\n",
    "threshold = np.mean(train_scores) + 2 * np.std(train_scores)\n",
    "print(f\"Belirlenen Threshold (SSIM Loss): {threshold:.4f}\")\n",
    "\n",
    "# 2. Test Aşaması\n",
    "test_path = f'/content/mvtec-ad/{category}/test'\n",
    "test_images = load_images(test_path)\n",
    "\n",
    "# Hesaplanan threshold değerini kullanıyoruz\n",
    "test_scores, is_anomaly, reconstructed = detect_anomalies(model, test_images, threshold=threshold)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_results(original, reconstructed, mse, n_samples=5):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Orijinal görüntü\n",
    "        plt.subplot(3, n_samples, i + 1)\n",
    "        plt.imshow(original[i])\n",
    "        plt.title(f'Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Rekonstrüksiyon\n",
    "        plt.subplot(3, n_samples, n_samples + i + 1)\n",
    "        plt.imshow(reconstructed[i])\n",
    "        plt.title(f'Reconstructed')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Fark haritası\n",
    "        plt.subplot(3, n_samples, 2*n_samples + i + 1)\n",
    "        diff = np.abs(original[i] - reconstructed[i])\n",
    "        plt.imshow(diff)\n",
    "        plt.title(f'MSE: {mse[i]:.4f}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_results(test_images, reconstructed, mse_scores)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_model(model, threshold, category=category):\n",
    "    # Normal örnekler\n",
    "    normal_path = f'/content/mvtec-ad/{category}/test/good'\n",
    "    normal_images = load_images(normal_path)\n",
    "\n",
    "    # SSIM Skorlarını al\n",
    "    normal_scores, _ = calculate_anomaly_scores(model, normal_images)\n",
    "\n",
    "    # Anomalili örnekler (tüm defekt tipleri)\n",
    "    anomaly_scores_list = []\n",
    "\n",
    "    test_path = Path(f'/content/mvtec-ad/{category}/test')\n",
    "    for defect_dir in test_path.iterdir():\n",
    "        if defect_dir.name != 'good' and defect_dir.is_dir():\n",
    "            anomaly_imgs = load_images(str(defect_dir))\n",
    "            if len(anomaly_imgs) > 0:\n",
    "                scores, _ = calculate_anomaly_scores(model, anomaly_imgs)\n",
    "                anomaly_scores_list.extend(scores)\n",
    "\n",
    "    anomaly_scores_np = np.array(anomaly_scores_list)\n",
    "\n",
    "    # Görselleştirme\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(normal_scores, bins=30, alpha=0.7, label='Normal (Clean)', color='green', density=True)\n",
    "    plt.hist(anomaly_scores_np, bins=30, alpha=0.7, label='Anomaly (Defect)', color='red', density=True)\n",
    "\n",
    "    # Threshold çizgisini ekle\n",
    "    plt.axvline(threshold, color='black', linestyle='--', label=f'Threshold: {threshold:.3f}')\n",
    "\n",
    "    plt.xlabel('Anomaly Score (1 - SSIM)')\n",
    "    plt.ylabel('Frequency (Density)')\n",
    "    plt.legend()\n",
    "    plt.title('SSIM Score Distribution: Normal vs Anomaly')\n",
    "    plt.show()\n",
    "\n",
    "    # İstatistikler\n",
    "    print(f\"Normal Score Mean: {normal_scores.mean():.6f} ± {normal_scores.std():.6f}\")\n",
    "    print(f\"Anomaly Score Mean: {anomaly_scores_np.mean():.6f} ± {anomaly_scores_np.std():.6f}\")\n",
    "\n",
    "    return normal_scores, anomaly_scores_np\n",
    "\n",
    "# Fonksiyonu yeni threshold ile çağır\n",
    "evaluate_model(model, threshold)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_images(data_path, img_size=(256, 256)):\n",
    "    images = []\n",
    "    path_obj = Path(data_path)\n",
    "    if not path_obj.exists():\n",
    "        print(f\"Uyarı: {data_path} yolu bulunamadı!\")\n",
    "        return np.array([])\n",
    "\n",
    "    for img_file in path_obj.glob('**/*.png'):\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None: continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# NOISE INJECTION FUNCTION\n",
    "def add_noise(images, noise_factor=0.1):\n",
    "    noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
    "    noisy_images = np.clip(noisy_images, 0., 1.)\n",
    "    return noisy_images\n",
    "\n",
    "category = 'leather'  # kategori\n",
    "base_path = '/content/mvtec-ad' if os.path.exists('/content/mvtec-ad') else '.'\n",
    "train_path = f'{base_path}/{category}/train/good'\n",
    "\n",
    "train_images_clean = load_images(train_path)\n",
    "# Add noise to create training inputs\n",
    "train_images_noisy = add_noise(train_images_clean, noise_factor=0.2)\n",
    "\n",
    "print(f\"Eğitim için {len(train_images_clean)} görüntü yüklendi.\")\n",
    "\n",
    "# Show example of noise\n",
    "if len(train_images_clean) > 0:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1); plt.imshow(train_images_clean[0]); plt.title('Clean')\n",
    "    plt.subplot(1, 2, 2); plt.imshow(train_images_noisy[0]); plt.title('Noisy (Input)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def build_autoencoder_simple(input_shape=(256, 256, 3)):\n",
    "    # Standard Autoencoder (Simpler than before to prevent Identity Mapping)\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), padding='same')(x) # 128\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), padding='same')(x) # 64\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = keras.layers.MaxPooling2D((2, 2), padding='same')(x) # 32x32 BOttleneck\n",
    "    # Note: We kept it slightly larger (32x32) because Denoising is the main regularizer now.\n",
    "    # If it still copies, we will reduce to 16x16.\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "    decoded = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = keras.Model(encoder_input, decoded)\n",
    "    return autoencoder\n",
    "\n",
    "model = build_autoencoder_simple()\n",
    "model.compile(optimizer='adam', loss=ssim_loss)\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "9CTy7t5B3wiK",
    "outputId": "450a8b85-7c00-4c6e-c3ae-567bc19cf712"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Eğitim\n",
    "if len(train_images_clean) > 0:\n",
    "    history = model.fit(\n",
    "        train_images_noisy, train_images_clean,  # Input: Noisy, Target: Clean\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "        ]\n",
    "    )\n",
    "    model.save('denoising_autoencoder.keras')\n",
    "else:\n",
    "    print(\"Eğitilecek veri bulunamadı.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hYuHgTXDOcM",
    "outputId": "229e2435-7eaa-41ee-afa3-d03edd5ac534"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def detect_anomalies_ssim(model, test_images):\n",
    "    if len(test_images) == 0: return [], [], []\n",
    "\n",
    "    # Rekonstrüksiyon\n",
    "    reconstructed = model.predict(test_images)\n",
    "\n",
    "    # SSIM MAP Computation\n",
    "    # tf.image.ssim returns a single score per image. We want a MAP.\n",
    "    # Unfortunately standard TF doesn't give Map easily. We can use abs diff for viz,\n",
    "    # but for scoring we use 1 - ssim.\n",
    "\n",
    "    # 1. SSIM Score (Global)\n",
    "    ssim_scores = tf.image.ssim(test_images, reconstructed, max_val=1.0).numpy()\n",
    "    anomaly_score = 1 - ssim_scores  # Higher score = More Anomaly\n",
    "\n",
    "    # 2. Difference Map (for Visualization)\n",
    "    diff_map = np.abs(test_images - reconstructed)\n",
    "    diff_map = np.mean(diff_map, axis=-1) # Grayscale difference\n",
    "\n",
    "    return anomaly_score, diff_map, reconstructed\n",
    "\n",
    "# Test veri yükleme\n",
    "test_path = f'{base_path}/{category}/test'\n",
    "test_images = load_images(test_path)\n",
    "\n",
    "if 'model' in locals() and len(test_images) > 0:\n",
    "    scores, diff_maps, reconstructed = detect_anomalies_ssim(model, test_images)\n",
    "\n",
    "    # Thresholding based on Scores\n",
    "    print(f\"Mean Score: {np.mean(scores):.4f}, Max Score: {np.max(scores):.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91eqikQ6EaYt",
    "outputId": "229e52b0-7ec9-4ee2-c751-6d65d12f41df"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_ssim_results(original, reconstructed, diff_maps, scores, n_samples=5):\n",
    "    if len(original) == 0: return\n",
    "    n_samples = min(n_samples, len(original))\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Orijinal\n",
    "        plt.subplot(3, n_samples, i + 1)\n",
    "        plt.imshow(original[i])\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Rekonstrüksiyon\n",
    "        plt.subplot(3, n_samples, n_samples + i + 1)\n",
    "        plt.imshow(reconstructed[i])\n",
    "        plt.title('Reconstructed')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Hata Haritası\n",
    "        plt.subplot(3, n_samples, 2*n_samples + i + 1)\n",
    "        plt.imshow(diff_maps[i], cmap='jet', vmin=0, vmax=0.3) # Jet cmap highlights defects\n",
    "        plt.title(f'Score: {scores[i]:.4f}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'scores' in locals() and len(test_images) > 0:\n",
    "    visualize_ssim_results(test_images, reconstructed, diff_maps, scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "zbjWQ2BDEe6q",
    "outputId": "625047a1-ea75-4799-a9f0-650a24eced54"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, category=category):\n",
    "    # Normal örnekler\n",
    "    normal_path = f'/content/mvtec-ad/{category}/test/good'\n",
    "    normal_images = load_images(normal_path)\n",
    "    normal_recon = model.predict(normal_images)\n",
    "    normal_mse = np.mean(np.square(normal_images - normal_recon), axis=(1,2,3))\n",
    "\n",
    "    # Anomalili örnekler (tüm defekt tipleri)\n",
    "    anomaly_mse = []\n",
    "    defect_types = []\n",
    "\n",
    "    test_path = Path(f'/content/mvtec-ad/{category}/test')\n",
    "    for defect_dir in test_path.iterdir():\n",
    "        if defect_dir.name != 'good' and defect_dir.is_dir():\n",
    "            anomaly_images = load_images(str(defect_dir))\n",
    "            anomaly_recon = model.predict(anomaly_images)\n",
    "            mse = np.mean(np.square(anomaly_images - anomaly_recon), axis=(1,2,3))\n",
    "            anomaly_mse.extend(mse)\n",
    "            defect_types.extend([defect_dir.name] * len(mse))\n",
    "\n",
    "    anomaly_mse = np.array(anomaly_mse)\n",
    "\n",
    "    # Görselleştirme\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(normal_mse, bins=30, alpha=0.7, label='Normal', color='green')\n",
    "    plt.hist(anomaly_mse, bins=30, alpha=0.7, label='Anomaly', color='red')\n",
    "    plt.xlabel('MSE')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.title('MSE Distribution: Normal vs Anomaly')\n",
    "    plt.show()\n",
    "\n",
    "    # İstatistikler\n",
    "    print(f\"Normal MSE: {normal_mse.mean():.6f} ± {normal_mse.std():.6f}\")\n",
    "    print(f\"Anomaly MSE: {anomaly_mse.mean():.6f} ± {anomaly_mse.std():.6f}\")\n",
    "    print(f\"Separation ratio: {anomaly_mse.mean() / normal_mse.mean():.2f}x\")\n",
    "\n",
    "    return normal_mse, anomaly_mse\n",
    "\n",
    "normal_scores, anomaly_scores = evaluate_model(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "K9Tk49DfH08k",
    "outputId": "0f15d1bb-c7f4-4735-f7a5-e0270ceb5ebc"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
